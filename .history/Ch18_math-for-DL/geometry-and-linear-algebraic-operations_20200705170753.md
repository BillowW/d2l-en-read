

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-05 17:06:57
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-05 17:07:43
 * @Description:
 * @TODO::
 * @Reference:
-->

## 总结

* 向量可以在几何上解释为空间中的点或方向。
* 点积将角度的概念定义为任意高维空间。
* 超平面是线和平面的高维概括。 它们可用于定义决策平面，这些决策平面通常用作分类任务的最后一步。
* 矩阵乘法可以在几何上解释为基础坐标的均匀变形。 它们代表了一种非常有限但数学上干净的向量转换方法。
* 线性相关性是一种判断向量集合何时处于比我们期望的空间空间小的方法的方法（例如，您有3个向量生活在二维空间中）。 矩阵的等级是线性独立的其列的最大子集的大小。
* 定义矩阵的逆矩阵后，矩阵求逆可以让我们找到另一个矩阵，该矩阵可以消除第一个矩阵的作用。 矩阵求逆理论上很有用，但由于数值不稳定，在实践中需要谨慎。
* 行列式使我们能够衡量矩阵扩展或缩小空间的程度。 非零行列式表示一个可逆的（非奇异）矩阵，零值行列式表示该矩阵是不可逆的（奇异）。
* 张量收缩和爱因斯坦求和为表达机器学习中看到的许多计算提供了一种简洁明了的符号。
