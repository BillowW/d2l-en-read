

<!--
 * @version:
 * @Author:  StevenJokes https://github.com/StevenJokes
 * @Date: 2020-07-02 18:37:33
 * @LastEditors:  StevenJokes https://github.com/StevenJokes
 * @LastEditTime: 2020-07-02 18:45:44
 * @Description:
 * @TODO::
 * @Reference:
-->

# 自动录制: 使用自动编码器进行评级预测

尽管矩阵分解模型在评级预测任务上取得了不错的表现，但它本质上是一个线性模型。 因此，这样的模型不能捕捉复杂的非线性和复杂的关系，这些关系可以预测用户的偏好。 在这一节中，我们介绍一个非线性神经网络 / 协同过滤模型，AutoRec [ Sedhain et al. ，2015](http://preview.d2l.ai/d2l-en/PR-1092/chapter_references/zreferences.html#sedhain-menon-sanner-ea-2015)。 它用一个自动编码器结构来识别协同过滤，目的是在显式反馈的基础上将非线性变换集成到自动编码器中。 神经网络已经被证明能够逼近任何连续函数，使它适合于解决矩阵分解的局限性和丰富矩阵分解的表达能力。

一方面，AutoRec 具有与自动编码器相同的结构，它由输入层、隐藏层和重构(输出)层组成。 自动编码器是一种神经网络，它学习将输入复制到输出，以便将输入编码到隐藏(通常是低维)表示中。 在 AutoRec 中，它不是显式地将用户 / 项嵌入到低维空间，而是使用交互矩阵的列 / 行作为输入，然后在输出层重新构造交互矩阵。

另一方面，AutoRec 不同于传统的自动编码器: AutoRec 关注于学习 / 重构输出层，而不是学习隐藏表示。 它使用部分观察到的交互矩阵作为输入，旨在重建一个完整的评级矩阵。 同时，为了推荐的目的，通过重构在输出层中填补输入的缺失项。

Autorec 有两个变体: 基于用户的和基于项目的。 为了简短起见，这里我们只介绍基于项的自动记录。 可以相应地派生出基于用户的 AutoRec。

## 模型


设$R_*i$表示评级矩阵的$i^th$列，其中未知评级默认为零。
神经结构被定义为:

TODO:MATH

其中 f (·) 和 g(·)代表激活函数，$W$ 和 $V$代表权重矩阵，$μ$和$b$代表偏差。 设 h (·) 表示 AutoRec 的整个网络。 输出TODO:MATH$h (R_*i)$是评分矩阵第 i 列的重构。

以下目标函数旨在最小化重构误差:

TODO:MATH

这里面，仅仅考虑了观测值的作用，即只更新了与观测值相关联的权系数。

## 实施模式

典型的自动编码器由编码器和解码器组成。 编码器将输入投影到隐藏表示，解码器将隐藏层映射到重构层。 我们按照这种做法，并创建了密集层（dense layers）的编码器和解码器。 编码器的激活默认设置为 sigmoid，解码器不激活。 在编码转换之后包括dropout，以减少过度拟合。 未观测输入的梯度被掩盖，以确保只有观测到的评分有助于模型学习过程。
